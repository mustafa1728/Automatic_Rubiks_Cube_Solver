{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cube solving.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y_q3QtwevXcn",
        "u6A6z3LcSAbB",
        "SorsRVzpPiU8",
        "JBrZHPhcTZkv",
        "kIUEYSWTMzvB",
        "bXI4yKi4UCC8",
        "r4tc_kQKvRWq"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T7JQOd4uQo9"
      },
      "source": [
        "#Cube Solver\n",
        "\n",
        "This project allows you to input images of the faces of a cube and prints out an algorithm to solve it. \n",
        "\n",
        "It uses Segmentation to detect the actual faces of the cube and then assumes a uniform 3*3 grid-like distribution to find the color of each piece.\n",
        "\n",
        "The logic used to assign colors is at: [line 28](https://colab.research.google.com/drive/1YyI__JZdwIeeSkUspFp_6xCb1ja0HgsA#scrollTo=5Wu-x2IlM5cV&line=28&uniqifier=1). Current logic: Find closest color from a set of 6 predefined colors (Logic needs to be changed with different cubes). I am working on clustering algorithms to solve this issue.\n",
        "\n",
        "Once the colors are detected, it is converted into a format according to [Kociemba Solver](https://colab.research.google.com/drive/1YyI__JZdwIeeSkUspFp_6xCb1ja0HgsA#scrollTo=5Wu-x2IlM5cV&line=28&uniqifier=1), and then solved by the Kociemba algorithm, which allows any configuration to be solved in less than 30 steps.\n",
        "\n",
        "The final output is an algorithm to solve the cube (and the number of steps)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoPWWf_XwT_K"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Instructions of use\n",
        "\n",
        "1. Upload the model weights file in your google drive and put its path [here](https://colab.research.google.com/drive/1YyI__JZdwIeeSkUspFp_6xCb1ja0HgsA#scrollTo=6LqqPSGQSGXJ&line=1&uniqifier=1) \n",
        "\n",
        "2.   Run the following cells in order upto the section 'Main Inference'. They have requirements and helper functions.\n",
        "3.   Readying inputs:\n",
        "    \n",
        "    a. take images of each face of the cube such that the image in the below figure would look straight.\n",
        "![rubik-flat.png](data:image/png;base64,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)\n",
        "    b. make a directory '/content/scramble/' and add the files in the format 'cube<i>.png' (This format can be changed by changing the final inference function.)\n",
        "4. run the final inference function to get the algorithms to solve the cube.\n",
        "The algorithm consists of a list of characters that follow [this convention](https://ruwix.com/the-rubiks-cube/notation/).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_q3QtwevXcn"
      },
      "source": [
        "#Installing requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTqZCWC1-VXq"
      },
      "source": [
        "This cell allows colab to connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUHu9iSsOnh2",
        "outputId": "fc16653d-74d6-4983-cba2-a60f99cb4533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg5BNhq6-djA"
      },
      "source": [
        "This cell copies the model codes and other requirements for Mask-RCNN stored in google drive.\n",
        " \n",
        "The github repo for Mask-RCNN is at: https://github.com/matterport/Mask_RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrgDBUVVO59s"
      },
      "source": [
        "!pip install pycuber\n",
        "!pip install rubik-solver\n",
        "!pip install kociemba\n",
        "# !sudo cp -avr /content/drive/My\\ Drive/cube\\ solver/Mask_RCNN /root/\n",
        "%cd ~/\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "%cd ~/Mask_RCNN/\n",
        "!sed -i -- 's/tensorflow>=1.3.0/tensorflow==1.15.2/g' requirements.txt\n",
        "!sed -i -- 's/keras>=2.0.8/keras==2.1.0/g' requirements.txt\n",
        "\n",
        "!pip install -q PyDrive\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6A6z3LcSAbB"
      },
      "source": [
        "#Top face Segmentation Model (Loading Weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbGI9poRC2wx"
      },
      "source": [
        "This code copies the weights of our trained models in the colab runtime. The weights are stored in Google Drive. The weights are then loaded and a model is initialised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LqqPSGQSGXJ"
      },
      "source": [
        "!cp /content/drive/My\\ Drive/cube\\ solver/models/50/mask_rcnn_cube_face_0070.h5 /root/Mask_RCNN/top_face_seg.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEO78Jt8SI5b"
      },
      "source": [
        "#important!!\n",
        "#if using extra conv layers for mask models, use mrcnn_conv in place of mrcnn\n",
        "%cd ~/Mask_RCNN\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "import time\n",
        "\n",
        "\n",
        "class_names = ['BG', 'cube face']\n",
        "\n",
        "# define the test configuration\n",
        "class TestConfig(Config):\n",
        "     NAME = \"test\"\n",
        "     GPU_COUNT = 1\n",
        "     IMAGES_PER_GPU = 1\n",
        "     NUM_CLASSES = 1 + 1\n",
        "     DETECTION_MIN_CONFIDENCE = 0.7\n",
        "\n",
        "# define the model\n",
        "rcnn_top_face = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n",
        "# load coco model weights\n",
        "# rcnn.load_weights(<weights_path>, by_name=True)\n",
        "\n",
        "rcnn_top_face.load_weights('/root/Mask_RCNN/top_face_seg.h5', by_name=True)\n",
        "#rcnn_box.keras_model.summary()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SorsRVzpPiU8"
      },
      "source": [
        "#Segmentation Inference codes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j13eMIw-xbi"
      },
      "source": [
        "This cell has some helper functions that are used in the main Segmentation function later on. These have been taken directly from the visualise.py file of the Mask RCNN implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR5n7A3Fk-gh"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import itertools\n",
        "import colorsys\n",
        "\n",
        "import numpy as np\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches,  lines\n",
        "from matplotlib.patches import Polygon\n",
        "import IPython.display\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "\n",
        "\n",
        "#\n",
        "def random_colors(N, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"Apply the given mask to the image.\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] *\n",
        "                                  (1 - alpha) + alpha * color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO2PvRfaAbsH"
      },
      "source": [
        "This cell has the main inference functions of segmentation. These have been taken from the visualise.py file of Mask-RCNN repo with some modifications added to get:\n",
        "\n",
        "1) Separate masks (in case of top face segmentation)\n",
        "\n",
        "2) Masks on top of original images with scores and bounding boxes (in case of box segmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Zn6BbIPnAJ"
      },
      "source": [
        "\n",
        "##My modifications are in the functions below\n",
        "\n",
        "#function for storing separate masks\n",
        "def display_instances(mask_path, image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=True,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "    # Generate random colors\n",
        "    colors = colors or random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "\n",
        "   \n",
        "    \n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "\n",
        "        # Mask\n",
        "        \n",
        "         #only mask will be a black image with masks\n",
        "        only_mask = np.zeros(masked_image.shape)\n",
        "\n",
        "\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask(masked_image, mask, color)\n",
        "            only_mask = apply_mask(only_mask, mask, color)\n",
        "            only_mask = np.float32(only_mask)\n",
        "            only_mask = cv2.cvtColor(only_mask, cv2.COLOR_BGR2RGB)\n",
        "            cv2.imwrite(mask_path + str(i+1) + '.jpg', only_mask)\n",
        "        \n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "\n",
        "    return masked_image.astype(np.uint8), N\n",
        "\n",
        "\n",
        "def save_results_top_face(img_path, save_path, mask_path):\n",
        "\n",
        "  img = load_img(img_path)\n",
        "  img = img_to_array(img)\n",
        "  # make prediction\n",
        "  results = rcnn_top_face.detect([img], verbose=0)\n",
        "  # get dictionary for first prediction\n",
        "  r = results[0]\n",
        "\n",
        "  res, no_of_stacks = display_instances(mask_path, img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n",
        "  res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "  cv2.imwrite(save_path, res)\n",
        "  time.sleep(1)\n",
        "  return no_of_stacks\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "\n",
        "#functioon for storing output with scores\n",
        "def display_instances_one_mask(save_path, image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=True,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "\n",
        "   \n",
        "    only_mask = np.zeros(masked_image.shape)\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "        ax.text(x1, y1 + 8, caption,\n",
        "                color='w', size=11, backgroundcolor=\"none\")\n",
        "\n",
        "        # Mask\n",
        "        \n",
        "         #only mask will be a black image with masks\n",
        "        \n",
        "\n",
        "\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask(masked_image, mask, color)\n",
        "            only_mask = apply_mask(only_mask, mask, color)\n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "    only_mask = np.float32(only_mask)\n",
        "    only_mask = cv2.cvtColor(only_mask, cv2.COLOR_BGR2RGB)\n",
        "    ax.imshow(masked_image.astype(np.uint8))\n",
        "    plt.savefig(save_path)\n",
        "    plt.close('all')\n",
        "\n",
        "    return masked_image.astype(np.uint8), N\n",
        "\n",
        "\n",
        "import cv2\n",
        "def save_results_boxes(img_path, save_path = '/root/Mask_RCNN/result.jpg', visualize = True):\n",
        "  img = load_img(img_path)\n",
        "  img = img_to_array(img)\n",
        "  results = rcnn_box.detect([img], verbose=0)\n",
        "  r = results[0]\n",
        "\n",
        "  res, n = display_instances_one_mask(save_path, img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n",
        "  res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "  if visualize:\n",
        "      print('Box seg-counting done')\n",
        "  boxes = r['rois']\n",
        "  boxes_to_pts_counter = 1\n",
        "  pts = []\n",
        "  box = boxes[0]\n",
        "  pts.append([[box[1], box[0]], [box[3], box[2]]])\n",
        "  while boxes_to_pts_counter < boxes.shape[0]:\n",
        "    if r['scores'][boxes_to_pts_counter]>0.9:\n",
        "        box = boxes[boxes_to_pts_counter]\n",
        "        pts.append([[box[1], box[0]], [box[3], box[2]]])\n",
        "    boxes_to_pts_counter +=1\n",
        "  n = template_match_thres_decay(img_path, pts, save_path)\n",
        "  if visualize:\n",
        "      print('Box template-counting done')\n",
        "  #cv2.imwrite(save_path, res)\n",
        "  time.sleep(1)\n",
        "  return n\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBrZHPhcTZkv"
      },
      "source": [
        "#Flat Extraction code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O7f4ZMbLTTq"
      },
      "source": [
        "This part allows us to convert the top surfaces into the front facing view (from any initial view) from the masks obtained in Top Face Segmentation.\n",
        "\n",
        "We use [Perspective Transform](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html) to get front view. We use Approx Polygon to find quadrilateral from masks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax16XyK8SDAX"
      },
      "source": [
        "import math\n",
        "import cv2\n",
        "import scipy.spatial.distance\n",
        "from scipy.spatial import distance as dist\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def order_points(pts, img):\n",
        "    return np.asarray([pts[0], pts[1], pts[3], pts[2]], dtype=pts.dtype)\n",
        "\n",
        "def get_perspective1(img_path, corners, save_path):\n",
        "    \n",
        "    img = cv2.imread(img_path)\n",
        "    points = order_points(corners, img)\n",
        "    #print(points)\n",
        "    pts1 = np.float32([points[0],points[1],points[2],points[3]])\n",
        "    W = 1024\n",
        "    H = 1024\n",
        "    pts2 = np.float32([[0,0],[W,0],[0,H],[W,H]])\n",
        "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "    imgOutput = cv2.warpPerspective(img,matrix,(W,H), flags=cv2.INTER_NEAREST)\n",
        "    if W>1.5 * H:\n",
        "        imgOutput = cv2.rotate(imgOutput, cv2.ROTATE_90_CLOCKWISE)\n",
        "    cv2.imwrite(save_path, imgOutput)\n",
        "\n",
        "\n",
        "def get_perspective(img_path, corners, save_path):\n",
        "    width = 1024\n",
        "    height = 1024\n",
        "    img = cv2.imread(img_path)\n",
        "    #print(img.shape)\n",
        "    #img = cv2.resize(img, (1422, 800)) \n",
        "    #print(img.shape)\n",
        "    [x_mean, y_mean] = np.mean(corners, axis = 0)\n",
        "    #y_mean = 800 - y_mean\n",
        "    #[x_max, y_max] = np.maximum(corners, axis = 0)\n",
        "    #[x_min, y_min] = np.minimum(corners, axis = 0)\n",
        "    new_corners = np.zeros((4,2),np.int)\n",
        "    i = 0\n",
        "    while i<4:\n",
        "        [x, y] = corners[i]\n",
        "        #y = 800 - y\n",
        "        if x<=x_mean and y<=y_mean:\n",
        "            new_corners[0] = [x, y]\n",
        "            #print(x, y)\n",
        "        elif x>x_mean and y<=y_mean:\n",
        "            new_corners[1] = [x, y]\n",
        "            #print(x, y)\n",
        "        elif x<=x_mean and y>y_mean:\n",
        "            new_corners[2] = [x, y]\n",
        "            #print(x, y)\n",
        "        elif x>x_mean and y>y_mean:\n",
        "            new_corners[3] = [x, y]\n",
        "            #print(x, y)\n",
        "        i = i+1\n",
        "    points = new_corners\n",
        "    pts1 = np.float32([points[0],points[1],points[2],points[3]])\n",
        "    pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
        "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "    imgOutput = cv2.warpPerspective(img,matrix,(width,height), flags=cv2.INTER_NEAREST)\n",
        "    cv2.imwrite(save_path, imgOutput)\n",
        "    \n",
        "\n",
        "##Auto contrast Code\n",
        "\n",
        "def automatic_brightness_and_contrast(image, clip_hist_percent=2):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate grayscale histogram\n",
        "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
        "    hist_size = len(hist)\n",
        "\n",
        "    # Calculate cumulative distribution from the histogram\n",
        "    accumulator = []\n",
        "    accumulator.append(float(hist[0]))\n",
        "    for index in range(1, hist_size):\n",
        "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
        "\n",
        "    # Locate points to clip\n",
        "    maximum = accumulator[-1]\n",
        "    clip_hist_percent *= (maximum/100.0)\n",
        "    clip_hist_percent /= 2.0\n",
        "\n",
        "    # Locate left cut\n",
        "    minimum_gray = 0\n",
        "    while accumulator[minimum_gray] < clip_hist_percent:\n",
        "        minimum_gray += 1\n",
        "\n",
        "    # Locate right cut\n",
        "    maximum_gray = hist_size -1\n",
        "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
        "        maximum_gray -= 1\n",
        "\n",
        "    # Calculate alpha and beta values\n",
        "    alpha = 255 / (maximum_gray - minimum_gray)\n",
        "    beta = -minimum_gray * alpha\n",
        "\n",
        "\n",
        "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return (auto_result, alpha, beta)\n",
        "\n",
        "\n",
        "def auto_cont(img_path, save_path):\n",
        "    image = cv2.imread(img_path)\n",
        "    auto_result, alpha, beta = automatic_brightness_and_contrast(image)\n",
        "    cv2.imwrite(save_path, auto_result)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#main flat extractor code\n",
        "def flat_extractor(input_image_path, mask_path, save_path):\n",
        "    original = cv2.imread(input_image_path)\n",
        "    mask = cv2.imread(mask_path)\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY )\n",
        "    ret,mask = cv.threshold(mask,10,255,cv.THRESH_BINARY)\n",
        "    mask_color = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR )\n",
        "    (cnts, _) = cv2.findContours(mask.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts=sorted(cnts, key = cv2.contourArea, reverse = True)\n",
        "    is_flat = False\n",
        "    for c in cnts:\n",
        "        peri = cv2.arcLength(c, True)\n",
        "        acc = 0.001\n",
        "        for i in range(100):\n",
        "            approx = cv2.approxPolyDP(c, i * acc * peri, True)\n",
        "            if len(approx)==4:\n",
        "                break \n",
        "        \n",
        "\n",
        "        if len(approx) == 4 and cv2.arcLength(approx,True) > 100:\n",
        "            #print(approx)\n",
        "            is_flat = True\n",
        "            cv2.drawContours(mask_color, [approx], -1, (0,255,0), 3)\n",
        "            cv2.drawContours(original, [approx], -1, (0,255,0), 3)\n",
        "            get_perspective(input_image_path, approx[:, 0, :],save_path)\n",
        "            #auto_cont(save_path, save_path)\n",
        "    return is_flat\n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIUEYSWTMzvB"
      },
      "source": [
        "#pyCube converter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wu-x2IlM5cV"
      },
      "source": [
        "from rubik_solver import utils\n",
        "import pycuber as pc\n",
        "from pycuber.solver import CFOPSolver\n",
        "from io import StringIO \n",
        "import sys\n",
        "from scipy.spatial import distance as dist\n",
        "\n",
        "cube_colors = [[255, 255, 255], [0, 255, 255], [255, 0, 0], [1, 255, 0], [0, 0, 225], [255, 255, 0]]\n",
        "cube_colors_names = ['white', 'yellow', 'blue', 'green', 'red', 'orange']\n",
        "color_map = {'white': 0, 'yellow': 1, 'blue': 3, 'green': 2, 'red': 4, 'orange': 5}\n",
        "#color_map = {'white': 5, 'yellow': 0, 'blue': 4, 'green': 2, 'red': 1, 'orange': 3}\n",
        "color_map_inv = {v: k for k, v in color_map.items()}\n",
        "color_map_rubik = {'white': 'w', 'yellow': 'y', 'blue': 'b', 'green': 'g', 'red': 'r', 'orange': 'o'}\n",
        "\n",
        "\n",
        "def get_colors(img):\n",
        "    h, w = img.shape[0:2]\n",
        "    colors = []\n",
        "    i = 0\n",
        "    while i < 9:\n",
        "        #print(i)\n",
        "        color = img[(h//3) * (i//3) + h//6, (w//3) * (i%3) + w//6]\n",
        "        colors.append(color)\n",
        "        i = i+1\n",
        "    #print(colors)\n",
        "    return colors\n",
        "\n",
        "def get_cube_color(color):\n",
        "\n",
        "    \n",
        "    #if (color[0]>200 and color[1]>200 and color[2]>200):\n",
        "    #    return cube_colors_names[0]\n",
        "    #elif (color[0]<50 and color[1]>220 and color[2]>200):\n",
        "    #    return cube_colors_names[1]\n",
        "    #elif (color[0]>200 and color[1]<50 and color[2]<50):\n",
        "    #    return cube_colors_names[2]\n",
        "    #elif (color[0]<50 and color[1]>100 and color[2]<50):\n",
        "    #    return cube_colors_names[3]\n",
        "    #elif (color[0]<50 and color[1]<50 and color[2]>200):\n",
        "    #    return cube_colors_names[4]\n",
        "    #elif (color[0]>200 and color[1]>200 and color[2]<50):\n",
        "    #    return cube_colors_names[5]\n",
        "    #else:\n",
        "    #    return cube_colors_names[2]\n",
        "    dist_min = 10000\n",
        "    j = 0\n",
        "    for i in range(6):\n",
        "        \n",
        "        distanc = dist.euclidean(cube_colors[i], color)\n",
        "        #np.sum(np.square(color - cube_colors[i]))\n",
        "        if distanc < dist_min:\n",
        "            j = i\n",
        "            dist_min = distanc\n",
        "            #print(dist)\n",
        "\n",
        "    return cube_colors_names[j]\n",
        "\n",
        "def get_cube_rubik(cube_flat):\n",
        "    s= color_map_rubik[color_map_inv[cube_flat[0]]]\n",
        "    i = 1\n",
        "    while i < len(cube_flat):\n",
        "        s= s + color_map_rubik[color_map_inv[cube_flat[i]]]\n",
        "        i=i+1\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_matrix(colors):\n",
        "\n",
        "    matrix = []\n",
        "    i = 0\n",
        "    print(colors)\n",
        "    while i <9:\n",
        "        matrix.append(get_cube_color(colors[i]))\n",
        "        i = i+1\n",
        "    #print(matrix)\n",
        "    return matrix\n",
        "\n",
        "\n",
        "def add_matrix(matrix, cube_flat):\n",
        "    center_color =  matrix[4]\n",
        "    #no = center_color\n",
        "    matrix_no = np.zeros(9)\n",
        "    for i in range(9):\n",
        "        matrix_no[i] = color_map[matrix[i]]\n",
        "\n",
        "    no = color_map[center_color]\n",
        "    cube_flat[9*no:9*no+9] = matrix_no\n",
        "    return cube_flat\n",
        "\n",
        "\n",
        "def combine_cube(cube_flat):\n",
        "    cube = pc.Cube()\n",
        "    sides = [cube.D, cube.U, cube.F, cube.B, cube.L, cube.R]\n",
        "    counter = 0 \n",
        "    for x in sides:\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                #print(x[i][j].colour)\n",
        "                #print(type(x[i][j]))\n",
        "                x[i][j] = Square(color_map_inv[cube_flat[counter]]) #color_map_rubik[color_map_inv[cube_flat[counter]]]\n",
        "                counter+=1\n",
        "                #print(counter, x[i][j], color_map_inv[cube_flat[counter-1]])\n",
        "    #print(cube)\n",
        "    return cube\n",
        "\n",
        "def get_list(img_format):\n",
        "    img_list = []\n",
        "    for i in range(1000):\n",
        "        img_path  = img_format + str(i+1) + '.jpg'\n",
        "        img = cv2.imread(img_path)\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img_list.append(img)\n",
        "    return(img_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zCGwDpMtIov"
      },
      "source": [
        "def cube_encode(img_list):\n",
        "    i = 0\n",
        "    cube_flat = np.zeros(54)\n",
        "    while i < len(img_list):\n",
        "        colors = get_colors(img_list[i])\n",
        "        matrix = get_matrix(colors)\n",
        "        add_matrix(matrix, cube_flat)\n",
        "        i = i+1\n",
        "    print(cube_flat)\n",
        "    cube = combine_cube(cube_flat)\n",
        "    return cube"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXI4yKi4UCC8"
      },
      "source": [
        "#Kociemba solver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WodzghPcI4aI"
      },
      "source": [
        "Efficient algorithm that solves any cube in upto 30 steps. This uses Group theory and DFS-type searching algorithms\n",
        "\n",
        "https://www.speedsolving.com/wiki/index.php/Kociemba%27s_Algorithm\n",
        "\n",
        "[wikipedia](https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik%27s_Cube)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXlhHBEBUEZz"
      },
      "source": [
        "import kociemba\n",
        "from rubik_solver import utils\n",
        "from io import StringIO \n",
        "import sys\n",
        "from scipy.spatial import distance as dist\n",
        "\n",
        "cube_colors = [[255, 255, 255], [0, 255, 255], [255, 0, 0], [1, 255, 0], [0, 0, 225], [0, 125, 255]]\n",
        "cube_colors_names = ['white', 'yellow', 'blue', 'green', 'red', 'orange']\n",
        "#color_map = {'white': 0, 'yellow': 1, 'blue': 3, 'green': 2, 'red': 4, 'orange': 5}\n",
        "color_map = {'white': 3, 'yellow': 0, 'blue': 5, 'green': 2, 'red': 4, 'orange': 1}\n",
        "color_map_inv = {v: k for k, v in color_map.items()}\n",
        "color_map_rubik = {'white': 'w', 'yellow': 'y', 'blue': 'b', 'green': 'g', 'red': 'r', 'orange': 'o'}\n",
        "kociemba_map = {'white': 'D', 'yellow': 'U', 'blue': 'B', 'green': 'F', 'red': 'L', 'orange': 'R'}\n",
        "\n",
        "def get_colors(img):\n",
        "    h, w = img.shape[0:2]\n",
        "    colors = []\n",
        "    i = 0\n",
        "    while i < 9:\n",
        "        #print(i)\n",
        "        color = img[(h//3) * (i//3) + h//6, (w//3) * (i%3) + w//6]\n",
        "        colors.append(color)\n",
        "        i = i+1\n",
        "    #print(colors)\n",
        "    return colors\n",
        "\n",
        "\n",
        "def get_cube_color(color):\n",
        "    dist_min = 10000\n",
        "    j = 0\n",
        "    for i in range(6):\n",
        "        \n",
        "        distanc = dist.euclidean(cube_colors[i], color)\n",
        "        #np.sum(np.square(color - cube_colors[i]))\n",
        "        if distanc < dist_min:\n",
        "            j = i\n",
        "            dist_min = distanc\n",
        "            #print(dist)\n",
        "\n",
        "    return cube_colors_names[j]\n",
        "\n",
        "def get_matrix(colors):\n",
        "\n",
        "    matrix = []\n",
        "    i = 0\n",
        "    #print(colors)\n",
        "    while i <9:\n",
        "        matrix.append(get_cube_color(colors[i]))\n",
        "        i = i+1\n",
        "    #print(matrix)\n",
        "    return matrix\n",
        "\n",
        "def add_matrix(matrix, cube_flat):\n",
        "    center_color =  matrix[4]\n",
        "    #no = center_color\n",
        "    matrix_no = np.zeros(9)\n",
        "    for i in range(9):\n",
        "        matrix_no[i] = color_map[matrix[i]]\n",
        "\n",
        "    no = color_map[center_color]\n",
        "    cube_flat[9*no:9*no+9] = matrix_no\n",
        "    return cube_flat\n",
        "\n",
        "\n",
        "def get_cube_kociemba(cube_flat):\n",
        "    s= kociemba_map[color_map_inv[cube_flat[0]]]\n",
        "    i = 1\n",
        "    while i < len(cube_flat):\n",
        "        s= s + kociemba_map[color_map_inv[cube_flat[i]]]\n",
        "        i=i+1\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWlz7KnumqXl"
      },
      "source": [
        "def cube_encode(img_list):\n",
        "    i = 0\n",
        "    cube_flat = np.zeros(54)\n",
        "    while i < len(img_list):\n",
        "        colors = get_colors(img_list[i])\n",
        "        matrix = get_matrix(colors)\n",
        "        add_matrix(matrix, cube_flat)\n",
        "        i = i+1\n",
        "    #print(cube_flat)\n",
        "    cube = get_cube_kociemba(cube_flat)\n",
        "    return cube"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4tc_kQKvRWq"
      },
      "source": [
        "#Final Inference Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB9H_LiX2M2d"
      },
      "source": [
        "def cube_solver(img_format, visualise = True):\n",
        "    no_of_boxes = []\n",
        "    img_list = []\n",
        "    if visualise:\n",
        "        print('The Cube is being converted...')\n",
        "    for i in range(1000):\n",
        "        mask_path = '/root/Mask_RCNN/mask'\n",
        "        #no_of_stacks = save_results_top_face(input_image_path, 'result.jpg', mask_path)\n",
        "\n",
        "        img_path  = img_format + str(i+1) + '.jpg'\n",
        "        img = cv2.imread(img_path)\n",
        "        if isinstance(img, np.ndarray):\n",
        "            \n",
        "            flat_save_path = '/root/Mask_RCNN/flat' + str(i+1) + '.jpg'\n",
        "            curent_mask_path = mask_path + str(1) + '.jpg'\n",
        "            no_of_stacks = save_results_top_face(img_path, 'result.jpg', mask_path)\n",
        "            is_flat = flat_extractor(img_path, curent_mask_path, flat_save_path)\n",
        "            if visualise:\n",
        "                if not is_flat:\n",
        "                    no_of_boxes.append(0)\n",
        "                    print('Face not detected!!!')\n",
        "                    print('==========')\n",
        "                    i = i+1\n",
        "                    continue\n",
        "                else:\n",
        "                    print('Face detected!')\n",
        "            img = cv2.imread(flat_save_path)\n",
        "            img_list.append(img)\n",
        "    cube = cube_encode(img_list)\n",
        "    #print(cube)\n",
        "    if visualise:\n",
        "        print('The cube is being solved...')\n",
        "    print('The algorithm to solve the cube is: ')\n",
        "    algo = kociemba.solve(cube)\n",
        "    print(algo)\n",
        "    steps = 1\n",
        "    for s in algo:\n",
        "        if s==' ':\n",
        "            steps += 1\n",
        "    print('No. of steps: ', steps)\n",
        "    #print(cube('F'))\n",
        "    #solver = CFOPSolver(cube)\n",
        "    #\n",
        "    #utils.solve(cube, 'CFOP')\n",
        "    #with Capturing() as output:\n",
        "    #    solver.solve()\n",
        "    #print('Solved!')\n",
        "    #print('The steps you need to solve the cube are: \\n \\n' + (output[-1][6:]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qSIlxTNtXEH"
      },
      "source": [
        "###Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QuhWiCOPGFQ"
      },
      "source": [
        "for i in range(6):\n",
        "#if True:        \n",
        "#        i = 2\n",
        "        img_format = '/content/scramble/cube'\n",
        "        img_path  = img_format + str(i+1) + '.jpg'\n",
        "        img = cv2.imread(img_path)\n",
        "        im_crop = img[650:1800, :]\n",
        "        cv2.imwrite(img_path, im_crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odbjGB8FvMuj"
      },
      "source": [
        "#Main Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ila1IEB9xt0S",
        "outputId": "9afbd6f3-84d8-47f7-b23f-9d3d0f2f861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cube_solver('/content/scramble/cube')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Cube is being converted...\n",
            "Face detected!\n",
            "Face detected!\n",
            "Face detected!\n",
            "Face detected!\n",
            "Face detected!\n",
            "Face detected!\n",
            "The cube is being solved...\n",
            "The algorithm to solve the cube is: \n",
            "R2 U F B2 R D L' U F' R' B' U R2 F2 L2 U R2 D B2 R2 F2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkcChHX5Dr_K",
        "outputId": "6bbb0052-6c24-40e8-ac66-f863e766acc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#cube = pc.Cube()\n",
        "print(cube)\n",
        "\n",
        "my_formula = pc.Formula(\"B U D B' R2 U' B' U B U' R U R' B U B' U2 B U2 B' U R' U' R L U L' U' L U L' U L' U' L U L' U2 L U' F' U' F' L F L' U F U2 F2 B2 D F2 B2 U F' B L2 F2 B2 R2 F' B U2 B U D B' R2 U' B' U B U' R U R' B U B' U2 B U2 B' U R' U' R L U L' U' L U L' U L' U' L U L' U2 L U' F' U' F' L F L' U F U2 F2 B2 D F2 B2 U F' B L2 F2 B2 R2 F' B U2\")\n",
        "cube(my_formula)\n",
        "#cube(my_formula)\n",
        "#cube(my_formula)\n",
        "#cube(my_formula)\n",
        "#cube(my_formula)\n",
        "#cube(my_formula)\n",
        "#solver = CFOPSolver(cube)\n",
        "#solver.solve()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         [y][y][y]\n",
            "         [y][y][y]\n",
            "         [y][y][y]\n",
            "[b][b][b][r][r][r][g][g][g][o][o][o]\n",
            "[b][b][b][r][r][r][g][g][g][o][o][o]\n",
            "[b][b][b][r][r][r][g][g][g][o][o][o]\n",
            "         [w][w][w]\n",
            "         [w][w][w]\n",
            "         [w][w][w]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      \u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\u001b[42m  \u001b[49m\n",
              "      \u001b[45m  \u001b[49m\u001b[43m  \u001b[49m\u001b[46m  \u001b[49m\n",
              "      \u001b[46m  \u001b[49m\u001b[45m  \u001b[49m\u001b[47m  \u001b[49m\n",
              "\u001b[43m  \u001b[49m\u001b[43m  \u001b[49m\u001b[45m  \u001b[49m\u001b[43m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[45m  \u001b[49m\u001b[47m  \u001b[49m\u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\u001b[41m  \u001b[49m\u001b[46m  \u001b[49m\n",
              "\u001b[46m  \u001b[49m\u001b[46m  \u001b[49m\u001b[42m  \u001b[49m\u001b[43m  \u001b[49m\u001b[45m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[42m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[45m  \u001b[49m\n",
              "\u001b[41m  \u001b[49m\u001b[46m  \u001b[49m\u001b[42m  \u001b[49m\u001b[45m  \u001b[49m\u001b[41m  \u001b[49m\u001b[47m  \u001b[49m\u001b[46m  \u001b[49m\u001b[42m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[47m  \u001b[49m\n",
              "      \u001b[43m  \u001b[49m\u001b[46m  \u001b[49m\u001b[45m  \u001b[49m\n",
              "      \u001b[43m  \u001b[49m\u001b[47m  \u001b[49m\u001b[45m  \u001b[49m\n",
              "      \u001b[46m  \u001b[49m\u001b[47m  \u001b[49m\u001b[41m  \u001b[49m"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHDKsMbfF8b_",
        "outputId": "6cd14b18-ebd4-4dd6-93a1-9eed5550aabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "my_formula = pc.Formula(\"B U D B' R2 U' B' U B U' R U R' B U B' U2 B U2 B' U R' U' R L U L' U' L U L' U L' U' L U L' U2 L U' F' U' F' L F L' U F U2 F2 B2 D F2 B2 U F' B L2 F2 B2 R2 F' B U2 B U D B' R2 U' B' U B U' R U R' B U B' U2 B U2 B' U R' U' R L U L' U' L U L' U L' U' L U L' U2 L U' F' U' F' L F L' U F U2 F2 B2 D F2 B2 U F' B L2 F2 B2 R2 F' B U2\")\n",
        "cube1 = cube(my_formula).copy()\n",
        "print(cube(my_formula))\n",
        "solver = CFOPSolver(cube)\n",
        "alg = solver.solve()\n",
        "cube\n",
        "print(cube1)\n",
        "alg = \"D' B D' B' D2 U R U' R' U2 R U' R' U F U2 F' U' B' U' B F U' F' L' U2 L U' F' L F R' F' L' F R U L U L' B' L U L' U' L' B L2 U' L' U'\"\n",
        " \n",
        "cube1(alg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         [b][y][o]\n",
            "         [w][y][r]\n",
            "         [r][b][w]\n",
            "[o][b][y][b][y][r][b][b][y][g][o][y]\n",
            "[w][b][b][o][r][w][g][g][r][g][o][r]\n",
            "[w][y][g][w][y][g][r][o][o][w][o][b]\n",
            "         [r][r][y]\n",
            "         [g][w][g]\n",
            "         [o][w][g]\n",
            "\n",
            "Solver starts....\rSolving Cross ......\u001b[2K\rCross: R' U2 D2 R2 B D2\n",
            "F2L('red', 'green'): F' U' F\n",
            "F2L('green', 'orange'): y R U R' F' U' F\n",
            "F2L('orange', 'blue'): y2 R U R' y' F' U F\n",
            "F2L('blue', 'red'): y U F' U2 F U F' U' F\n",
            "OLL:  U2 R U R' U R d' R U' R' F'\n",
            "PLL:  y M2 U M2 U M' U2 M2 U2 M' U2\n",
            "\n",
            "FULL: R' U2 D2 R2 B D2 F' U' F B U B' R' U' R F U F' B' U B U L' U2 L U L' U' L U2 F U F' U F U' R U' R' F B2 D B2 F2 U B' F R2 B2 F2 L2 B' F U2\n",
            "         [o][y][g]\n",
            "         [g][y][o]\n",
            "         [b][b][r]\n",
            "[y][y][r][y][w][w][g][b][o][y][o][b]\n",
            "[r][b][w][r][r][g][o][g][w][g][o][y]\n",
            "[o][r][r][y][b][b][r][g][w][g][o][w]\n",
            "         [g][y][w]\n",
            "         [b][w][r]\n",
            "         [b][w][o]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      \u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\u001b[42m  \u001b[49m\n",
              "      \u001b[47m  \u001b[49m\u001b[43m  \u001b[49m\u001b[46m  \u001b[49m\n",
              "      \u001b[46m  \u001b[49m\u001b[41m  \u001b[49m\u001b[42m  \u001b[49m\n",
              "\u001b[43m  \u001b[49m\u001b[45m  \u001b[49m\u001b[45m  \u001b[49m\u001b[43m  \u001b[49m\u001b[46m  \u001b[49m\u001b[45m  \u001b[49m\u001b[47m  \u001b[49m\u001b[43m  \u001b[49m\u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\u001b[41m  \u001b[49m\u001b[46m  \u001b[49m\n",
              "\u001b[42m  \u001b[49m\u001b[46m  \u001b[49m\u001b[47m  \u001b[49m\u001b[46m  \u001b[49m\u001b[45m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[42m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\n",
              "\u001b[41m  \u001b[49m\u001b[43m  \u001b[49m\u001b[43m  \u001b[49m\u001b[42m  \u001b[49m\u001b[45m  \u001b[49m\u001b[45m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[47m  \u001b[49m\u001b[42m  \u001b[49m\u001b[41m  \u001b[49m\u001b[47m  \u001b[49m\n",
              "      \u001b[45m  \u001b[49m\u001b[46m  \u001b[49m\u001b[46m  \u001b[49m\n",
              "      \u001b[45m  \u001b[49m\u001b[47m  \u001b[49m\u001b[45m  \u001b[49m\n",
              "      \u001b[46m  \u001b[49m\u001b[47m  \u001b[49m\u001b[41m  \u001b[49m"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    }
  ]
}